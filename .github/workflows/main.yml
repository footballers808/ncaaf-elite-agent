name: NCAAF Elite Agent

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "Mode to run"
        required: true
        default: "predict"
      week:
        description: "ISO week (yyyy-ww) or 'auto'"
        required: false
        default: "auto"
      commit_best:
        description: "If 'true', open a PR applying the merged tuned config"
        required: false
        default: "false"
  schedule:
    - cron: "0 13 * * 1"   # Mondays 13:00 UTC

permissions:
  contents: write

concurrency:
  group: ncaaf-elite-agent-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    env:
      PYTHONDONTWRITEBYTECODE: "1"
      # CFBD throttling defaults (learn/tune can override per-step if desired)
      CFBD_API_KEY:        ${{ secrets.CFBD_API_KEY }}
      CFBD_MIN_SLEEP_MS:   "1000"
      CFBD_MAX_RETRIES:    "12"
      CFBD_BACKOFF_BASE_S: "2.0"

      # Email (optional)
      SMTP_HOST:     ${{ secrets.SMTP_HOST }}
      SMTP_PORT:     ${{ secrets.SMTP_PORT }}
      SMTP_USER:     ${{ secrets.SMTP_USER }}
      SMTP_PASS:     ${{ secrets.SMTP_PASS }}
      FROM_ADDR:     ${{ secrets.FROM_ADDR }}
      TO_ADDRS:      ${{ secrets.TO_ADDRS }}

      # Slack (optional)
      SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      # ---------- CACHES ----------
      - name: Cache CFBD responses
        uses: actions/cache@v4
        with:
          path: .cache/cfbd
          key: cfbd-${{ runner.os }}-v1
          restore-keys: |
            cfbd-${{ runner.os }}-

      - name: Restore penalty features cache
        uses: actions/cache@v4
        with:
          path: artifacts/features
          key: penalties-${{ runner.os }}-v1
          restore-keys: |
            penalties-${{ runner.os }}-

      # ---------- CONFIG CHECK ----------
      - name: Apply tuned config (if present) + validate
        if: ${{ github.event.inputs.mode != 'tune' && github.event.inputs.mode != '' }}
        run: |
          if [ -f tuning-results/best_config.yaml ]; then
            echo "Found tuning-results/best_config.yaml"
            if [ -f tools/apply_best_config.py ]; then
              python tools/apply_best_config.py
              cp config.merged.yaml config.yaml || true
            else
              echo "No apply_best_config.py; skipping auto-merge."
            fi
          else
            echo "No tuning-results/best_config.yaml; using repo config.yaml"
          fi
          if [ -f tools/validate_config.py ]; then
            python tools/validate_config.py
          else
            echo "No validate script found; skipping."
          fi

      # ---------- WARMUP (lighter + quick retries) ----------
      - name: Build penalty features (warmup)
        if: ${{ github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'learn' || github.event.inputs.mode == 'backtest' || github.event.inputs.mode == 'tune' }}
        env:
          CFBD_MAX_RETRIES: "3"
          CFBD_MIN_SLEEP_MS: "1500"
        run: |
          set -e
          tries=0
          until [ $tries -ge 1 ]
          do
            python -m src.data_penalties --years 1 --windows 3,5,10 && break
            tries=$((tries+1))
            echo "Warmup retry ${tries}/1..."
            sleep 10
          done || true

      - name: Save penalty features cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: artifacts/features
          key: penalties-${{ runner.os }}-v1

      # ---------- MODES ----------
      - name: Predict
        if: ${{ github.event.inputs.mode == 'predict' }}
        run: |
          python -m src.predict --week "${{ github.event.inputs.week }}" --out artifacts/predictions.csv
          python -m src.odds   --week "${{ github.event.inputs.week }}" --out artifacts/market_lines.csv || true
          python -m src.edges  --pred artifacts/predictions.csv --lines artifacts/market_lines.csv --out artifacts/edges.csv || true
          python -m src.report --week "${{ github.event.inputs.week }}" --pred artifacts/predictions.csv --edges artifacts/edges.csv --out artifacts/report.html || true

      - name: Label
        if: ${{ github.event.inputs.mode == 'label' }}
        run: |
          python -m src.label --week "${{ github.event.inputs.week }}" --out artifacts/labels.csv

      - name: Learn
        if: ${{ github.event.inputs.mode == 'learn' }}
        run: |
          set -e
          build_features () {
            YEARS=$1
            echo "== Building penalty features (years=${YEARS}) =="
            tries=0
            until [ $tries -ge 3 ]
            do
              python -m src.data_penalties --years ${YEARS} --windows 3,5,10 && return 0
              tries=$((tries+1))
              echo "Retry ${tries}/3 for years=${YEARS}..."
              sleep 25
            done
            return 1
          }
          if [ ! -f artifacts/features/penalties.parquet ]; then build_features 1 || true; fi
          if [ ! -f artifacts/features/penalties.parquet ]; then build_features 2 || true; fi
          if [ ! -f artifacts/features/penalties.parquet ]; then build_features 3 || true; fi
          if [ ! -f artifacts/features/penalties.parquet ]; then
            echo "ERROR: penalties.parquet still missing after fallbacks."
            exit 1
          fi
          python -m src.learn --years 5 --save artifacts/model.joblib

      - name: Report
        if: ${{ github.event.inputs.mode == 'report' }}
        run: |
          python -m src.report --week "${{ github.event.inputs.week }}" --pred artifacts/predictions.csv --edges artifacts/edges.csv --out artifacts/report.html

      - name: Backtest
        if: ${{ github.event.inputs.mode == 'backtest' }}
        env:
          BACKTEST_STRICT: "0"
        run: |
          python -u -m src.backtest --years 2 --season-type regular --out artifacts/backtest.json

      - name: Tune
        if: ${{ github.event.inputs.mode == 'tune' }}
        env:
          TUNE_ITERS: "8"
          TUNE_FAIL_OPEN: "1"
        run: |
          python -m src.tune

      # ---------- ARTIFACTS ----------
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-artifacts
          path: |
            artifacts/**
            tuning-results/**
          if-no-files-found: ignore
          retention-days: 7

      - name: Commit merged tuned config to branch
        if: ${{ github.event.inputs.commit_best == 'true' && hashFiles('config.merged.yaml') != '' }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          BR="auto/best-config-${{ github.run_id }}"
          git checkout -b "$BR"
          cp config.merged.yaml config.yaml
          git add config.yaml
          git commit -m "chore: apply best_config.yaml (run ${{ github.run_id }})"
          git push -u origin "$BR"
          echo "PR step created. Open it to merge the tuned config."

      - name: Email report
        if: ${{ env.SMTP_HOST != '' && (github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'report') }}
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: ${{ env.SMTP_HOST }}
          server_port: ${{ env.SMTP_PORT }}
          username: ${{ env.SMTP_USER }}
          password: ${{ env.SMTP_PASS }}
          subject: "NCAAF Agent – ${{ github.event.inputs.mode }} – run ${{ github.run_id }}"
          from: ${{ env.FROM_ADDR }}
          to: ${{ env.TO_ADDRS }}
          content_type: text/html
          convert_markdown: false
          attachments: |
            artifacts/report.html
            artifacts/edges.csv
            artifacts/predictions.csv

      - name: Slack webhook
        if: ${{ env.SLACK_WEBHOOK != '' && (github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'report') }}
        run: |
          if [ -f artifacts/edges.csv ]; then
            MSG="Edges ready for ${{ github.event.inputs.mode }} (run ${{ github.run_id }})"
          else
            MSG="No edges.csv found for ${{ github.event.inputs.mode }} (run ${{ github.run_id }})"
          fi
          curl -X POST -H "Content-type: application/json" \
            --data "{\"text\":\"${MSG}\"}" "$SLACK_WEBHOOK"
