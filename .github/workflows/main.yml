name: NCAAF Elite Agent

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "Mode to run"
        required: true
        default: "learn"
      week:
        description: "ISO week (yyyy-ww) or 'auto'"
        required: false
        default: "auto"
      commit_best:
        description: "If 'true', open a PR applying the merged tuned config"
        required: false
        default: "false"
  schedule:
    - cron: "0 13 * * 1"   # Mondays 13:00 UTC

permissions:
  contents: write

concurrency:
  group: ncaaf-elite-agent-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    env:
      PYTHONDONTWRITEBYTECODE: "1"

      # CFBD throttle knobs (increase if you still hit limits)
      CFBD_API_KEY:        ${{ secrets.CFBD_API_KEY }}
      CFBD_MIN_SLEEP_MS:   "2000"
      CFBD_MAX_RETRIES:    "20"
      CFBD_BACKOFF_BASE_S: "2.2"

      # Email (optional)
      SMTP_HOST:     ${{ secrets.SMTP_HOST }}
      SMTP_PORT:     ${{ secrets.SMTP_PORT }}
      SMTP_USER:     ${{ secrets.SMTP_USER }}
      SMTP_PASS:     ${{ secrets.SMTP_PASS }}
      FROM_ADDR:     ${{ secrets.FROM_ADDR }}
      TO_ADDRS:      ${{ secrets.TO_ADDRS }}

      # Slack (optional)
      SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      # ---------- CACHES ----------
      - name: Cache CFBD responses
        uses: actions/cache@v4
        with:
          path: .cache/cfbd
          key: cfbd-${{ runner.os }}-v1
          restore-keys: |
            cfbd-${{ runner.os }}-

      - name: Restore penalty features cache
        uses: actions/cache@v4
        with:
          path: artifacts/features
          key: penalties-${{ runner.os }}-v1
          restore-keys: |
            penalties-${{ runner.os }}-

      # ---------- CONFIG CHECK ----------
      - name: Apply tuned config (if present) + validate
        if: ${{ github.event.inputs.mode != 'tune' && github.event.inputs.mode != '' }}
        run: |
          if [ -f tuning-results/best_config.yaml ]; then
            echo "Found tuning-results/best_config.yaml"
            if [ -f tools/apply_best_config.py ]; then
              python tools/apply_best_config.py
              cp config.merged.yaml config.yaml || true
            else
              echo "No apply_best_config.py; skipping auto-merge."
            fi
          else
            echo "No tuning-results/best_config.yaml; using repo config.yaml"
          fi
          if [ -f tools/validate_config.py ]; then
            python tools/validate_config.py
          else
            echo "No validate script found; skipping."
          fi

      # ---------- STRICT FEATURE BACKFILL ----------
      - name: Backfill penalties (strict, staged 5→3→1)
        if: ${{ github.event.inputs.mode == 'learn' || github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'backtest' }}
        run: |
          set -e
          mkdir -p artifacts/features

          build_stage () {
            YEARS=$1
            echo "== Building penalty features for last ${YEARS} season(s) =="
            tries=0
            until [ $tries -ge 3 ]
            do
              python -m src.data_penalties --years ${YEARS} --windows 3,5,10 && return 0
              tries=$((tries+1))
              echo "Retry ${tries}/3 for years=${YEARS}..."
              sleep $(( 20 + 10*tries ))
            done
            return 1
          }

          # Oldest→newest reduces rate-limit spikes
          build_stage 5 || true
          build_stage 3 || true
          build_stage 1 || true

          if [ ! -f artifacts/features/penalties.parquet ]; then
            echo "ERROR: penalties.parquet missing after strict backfill; aborting."
            exit 1
          fi

      - name: Save penalty features cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: artifacts/features
          key: penalties-${{ runner.os }}-v1

      # ---------- MODES ----------
      - name: Predict (scores + win prob)
        if: ${{ github.event.inputs.mode == 'predict' }}
        run: |
          python -m src.predict --week "${{ github.event.inputs.week }}" --out artifacts/win_predictions.csv || true
          python -m src.score_predict --week "${{ github.event.inputs.week }}" --out artifacts/score_predictions.csv
          python -m src.report --week "${{ github.event.inputs.week }}" \
            --pred artifacts/win_predictions.csv \
            --edges artifacts/score_predictions.csv \
            --out artifacts/report.html || true

      - name: Label
        if: ${{ github.event.inputs.mode == 'label' }}
        run: |
          python -m src.label --week "${{ github.event.inputs.week }}" --out artifacts/labels.csv

      # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
      #                            LEARN (STRICT)
      # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
      - name: Learn (strict, real data only)
        if: ${{ github.event.inputs.mode == 'learn' }}
        run: |
          set -e
          # Train win-prob model (classification) on 5 seasons
          python -m src.learn --years 5 --save artifacts/model_cls.joblib --features artifacts/features/penalties.parquet
          # Train score models (home & away points) on 5 seasons
          python -m src.score_learn --years 5 \
            --features artifacts/features/penalties.parquet \
            --save-home artifacts/model_homepts.joblib \
            --save-away artifacts/model_awaypts.joblib \
            --metrics artifacts/score_metrics.json

      - name: Report
        if: ${{ github.event.inputs.mode == 'report' }}
        run: |
          python -m src.report --week "${{ github.event.inputs.week }}" --pred artifacts/win_predictions.csv --edges artifacts/score_predictions.csv --out artifacts/report.html

      - name: Backtest
        if: ${{ github.event.inputs.mode == 'backtest' }}
        run: |
          python -u -m src.backtest --years 3 --season-type regular --out artifacts/backtest.json

      - name: Tune
        if: ${{ github.event.inputs.mode == 'tune' }}
        env:
          TUNE_ITERS: "12"
        run: |
          python -m src.tune

      # ---------- ARTIFACTS ----------
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-artifacts
          path: |
            artifacts/**
            tuning-results/**
          if-no-files-found: ignore
          retention-days: 7

      - name: Email report
        if: ${{ env.SMTP_HOST != '' && (github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'report') }}
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: ${{ env.SMTP_HOST }}
          server_port: ${{ env.SMTP_PORT }}
          username: ${{ env.SMTP_USER }}
          password: ${{ env.SMTP_PASS }}
          subject: "NCAAF Agent – ${{ github.event.inputs.mode }} – run ${{ github.run_id }}"
          from: ${{ env.FROM_ADDR }}
          to: ${{ env.TO_ADDRS }}
          content_type: text/html
          convert_markdown: false
          attachments: |
            artifacts/report.html
            artifacts/score_predictions.csv

      - name: Slack webhook
        if: ${{ env.SLACK_WEBHOOK != '' && (github.event.inputs.mode == 'predict' || github.event.inputs.mode == 'report') }}
        run: |
          MSG="Run ${{ github.run_id }} finished – mode=${{ github.event.inputs.mode }}"
          curl -X POST -H "Content-type: application/json" \
            --data "{\"text\":\"${MSG}\"}" "$SLACK_WEBHOOK"
